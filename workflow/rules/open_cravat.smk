# Functions and rules for running OpenCRAVAT
from scripts.common import abstract_location, allocated

# Germline OpenCravat Rules 
rule chrom_selectvariants:
    """
    Makes per-chromosome jointly called VCFs from GLnexus output. Please note 
    OpenCRAVAT should not be run with a normalized VCF file (i.e. output from 
    'vt decompose' or 'bcftools norm') as information from multi-allelic sites 
    are lost in the resulting OpenCRAVAT SQLite file. This step is used to speed 
    up the remaining OpenCRAVAT rules. At the end, the resulting SQLite databases 
    are merged back together (gather-step) for each chromosome.
    @Input:
        Multi-sample joint VCF file (scatter)
    @Output:
        Chromosome chunked joint VCF file
    """
    input: 
        vcf = join(workpath, "deepvariant", "VCFs", "joint.glnexus.vcf.gz"),
    output: 
        vcf = join(workpath, "OpenCRAVAT", "germline", "VCFs", "{chunk}.germline.vcf.gz"),
    params: 
        rname  = "chrselect",
        genome = config['references']['GENOME'], 
        chrom  = "{chunk}", 
        # For UGE/SGE clusters memory is allocated
        # per cpu, so we must calculate total mem
        # as the product of threads and memory
        memory    = lambda _: int(
            int(allocated("mem", "chrom_selectvariants", cluster).lower().rstrip('g')) * \
            int(allocated("threads", "chrom_selectvariants", cluster)) 
        )-1 if run_mode == "uge" \
        else allocated("mem", "chrom_selectvariants", cluster).lower().rstrip('g'),
    threads: int(allocated("threads", "chrom_selectvariants", cluster))
    container: config['images']['genome-seek']
    envmodules: 
        config['tools']['gatk4'], 
        config['tools']['bcftools'],
    shell: """
    gatk --java-options '-Xmx{params.memory}g -XX:ParallelGCThreads={threads}' SelectVariants \\
        -R {params.genome} \\
        --variant {input.vcf} \\
        -L {params.chrom} \\
        --exclude-non-variants \\
        --output {output.vcf}
    
    tabix --force \\
        -p vcf {output.vcf}
    """


rule opencravat_germline:
    """
    Performs genomic variant interpretation including variant impact, annotation,
    and scoring using OpenCRAVAT. Creates a SQLite database that can be used 
    with OpenCRAVAT's user interface. Here is more information about OpenCRAVAT: 
    https://open-cravat.readthedocs.io/en/latest/
    @Input:
        Chromosome chunked joint VCF file (scatter)
    @Output:
        Chromosome chunked SQLite OpenCravat results
    """
    input: 
        vcf = join(workpath, "OpenCRAVAT", "germline", "VCFs", "{chunk}.germline.vcf.gz"),
    output: 
        db = join(workpath, "OpenCRAVAT", "germline", "cravat_{chunk}.sqlite"),
    params: 
        rname  = "ocrungermline",
        prefix = "cravat_{chunk}",
        outdir = join(workpath, "OpenCRAVAT", "germline"),
        annot  = ' '.join(config['options']['oc_annotators']),
        genome = config['references']['OC_LIFTOVER'],
        module = config['references']['OC_MODULES'],
    threads: int(allocated("threads", "opencravat_germline", cluster))
    container: config['images']['open_cravat']
    envmodules: config['tools']['open_cravat']
    shell: """
    # Environment variable for modules dir
    export OC_MODULES="{params.module}"
 
    oc run \\
        -t vcf \\
        -x \\
        --newlog \\
        --cleanrun \\
        --system-option "modules_dir={params.module}" \\
        -a {params.annot} \\
        -n {params.prefix} \\
        -l {params.genome} \\
        -d {params.outdir} \\
        --mp {threads} \\
        {input.vcf}
    """


# TODO: convert this into a script
rule opencravat_germline_filter:
    """
    Performs additional filtering on the SQLite file generated by OpenCRAVAT.
    The filter options provided by OpenCRAVAT were not working correctly. An issue
    with the maintainers of the tool have been opened up. This rule is effectively
    a patch and may not be used in the near future. Each script that is generated
    performs additional rounds of filtering. 

    @filter_1: Filters variants based on sequence ontology and allele frequency 
    in public databases.
        @criteria: 
        Sequence ontology one of the given list of SO in the config file
            AND
        GNOMAD AF < 0.001 OR GNOMAD3 AF < 0.001 OR 1000Genome AF < 0.001 
            OR 
        all GNOMAD, GNOMAD3 and 1000Genome AF are missing
    
    @filter_2: Filter variants based on criteria given in the config.json 
    "secondary" group. To add filter move an annotator from "notused" group 
    to "secondary" group. Additional filter criterion can be added in the 
    config.json in the folloing format:
        "annotator": {
            "col" : "column of annotator to use"
            "relation" : "<, <=, >, >="  # for numeric values or "IN" for character values
            "value": "value to use for filter"
        }
    Note, if multiple column of same annotator need to be used for filtering using the 
    following format:
        "annotator": {
            "col": "multiple",
            "cols" : "col1,col2",
            "relation": "relation1,relation2",
            "value": "value1,value2"
        }
    
    @fix_column: By default, OpenCRAVAT has vcf_info total reads as string that includes 
    reads from all the samples that contains the variant. This rule creates an additional
    column with max and min of total reads and max and min of AF.
    @Input:
        Chromosome chunked SQLite OpenCravat results
    @Output:
        Filtered, fixed chromosome chunked SQLite OpenCravat results
    """
    input: 
        db = join(workpath, "OpenCRAVAT", "germline", "cravat_{chunk}.sqlite"),
    output:
        filter_1 = join(workpath, "OpenCRAVAT", "germline", "filter", "cravat_{chunk}.f1.sqlite"),
        filter_2 = join(workpath, "OpenCRAVAT", "germline", "filter", "cravat_{chunk}.f2.sqlite"),
        fixed    = join(workpath, "OpenCRAVAT", "germline", "filter", "cravat_{chunk}.fixed.sqlite"),
    params: 
        rname  = "ocfiltergermline",
        chrom  = "{chunk}",
        annot  = config['options']['oc_annotators'],
        scripts  = join(workpath, "OpenCRAVAT", "germline", "scripts"),
        filter_1 = join(workpath, "OpenCRAVAT", "germline", "scripts", "filter_1_{chunk}.py"),
        filter_2 = join(workpath, "OpenCRAVAT", "germline", "scripts", "filter_2_{chunk}.py"),
        fixed    = join(workpath, "OpenCRAVAT", "germline", "scripts", "fix_column_{chunk}.py"),
        # Default pop_maf: 0.05 
        maf_thres = config['options']['cravat_filters']['primary']['pop_maf'],
        so = config['options']['cravat_filters']['primary']['so'],
        secondary = config['options']['cravat_filters']['secondary'],
    message: "Running OpenCRAVAT filters on '{input.db}' input file"
    threads: int(allocated("threads", "opencravat_germline_filter", cluster))
    container: config['images']['genome-seek']
    envmodules: 
        # Requires sqlite3, added in python/3.5
        config['tools']['python3']
    shell: """
# Create first filtering script,
# Filters based on AF 
mkdir -p {params.scripts}
cp {input.db} {output.filter_1} 
cat << EOF > {params.filter_1}
import sqlite3
import os

maf = str({params.maf_thres})
mafc = str(1 - float({params.maf_thres}))
so = "{params.so}"
conn = sqlite3.connect("{output.filter_1}")
conn.isolation_level = None
cursor = conn.cursor()
conn.execute('CREATE TABLE variant2 AS SELECT * FROM variant WHERE (base__so IN (' + '"' + '", "'.join(so.split(',')) + '"' + ')) AND ((gnomad__af IS NULL AND gnomad3__af IS NULL AND thousandgenomes__af IS NULL) OR (gnomad__af <= ' + maf +' OR gnomad__af >= '+mafc+' OR gnomad3__af <= '+maf+' OR gnomad3__af >= '+mafc+' OR thousandgenomes__af <= '+maf+' OR thousandgenomes__af >= '+mafc+'))')
conn.execute('DROP TABLE variant')
conn.execute('ALTER TABLE variant2 RENAME TO variant')
conn.execute('DELETE from sample WHERE base__uid NOT IN (SELECT base__uid FROM variant)')
conn.execute('DELETE FROM gene WHERE base__hugo NOT IN (SELECT base__hugo FROM variant)')
conn.execute('DELETE FROM mapping WHERE base__uid NOT IN (SELECT base__uid FROM variant)')
conn.execute('UPDATE info SET colval = (SELECT COUNT(*) FROM variant) WHERE colkey == "Number of unique input variants"')
conn.execute('VACUUM')
conn.close()
EOF

# Create second filtering script,
# Filters based on filters in config
cp {output.filter_1} {output.filter_2}
cat << EOF > {params.filter_2}
import pandas as pd
import sqlite3
import os

conn = sqlite3.connect("{output.filter_2}")
conn.isolation_level = None
cursor = conn.cursor()
filter = {params.secondary}

def keep(dd, used_annotators):
    final_annotators = {{annotator: dd[annotator] for annotator in used_annotators}}
    return final_annotators

def filtercol(dd, annot):
    if dd['relation']=='IN':
        return annot + '__' + dd['col'] + ' ' + dd['relation'] + ' ("' + '", "'.join(dd['value'].split(',')) + '")'
    elif dd['relation']=='IS' or dd['relation']=='IS NOT':
        return annot + '__' + dd['col'] + ' ' + dd['relation'] + ' ' + dd['value']
    else:
        return annot + '__'+ dd['col'] + ' ' + dd['relation'] + dd['value']    

def filterunit(annot):
    dd = filter[annot]
    if dd['col'].lower()=='multiple':
        cols = dd['cols'].split(',')
        relations = dd['relation'].split(',')
        values = dd['value'].split(',')
        return(' OR '.join([filtercol({{'col':cols[0], 'relation': relations[0], 'value': values[0]}}, annot) for i in range(len(cols))]))
    else:
        return(filtercol(dd, annot))

def filterunit_null(annot):
    dd = filter[annot]
    if dd['col'].lower()=='multiple':
        cols = dd['cols'].split(',')
        relations = dd['relation'].split(',')
        values = dd['value'].split(',')
        return(' AND '.join([annot + '__' + cols[i] + ' IS NULL' for i in range(len(cols))]))
    else:
        return(annot + '__' + dd['col'] + ' IS NULL')

# Find the intersect of annotators listed
# in colnames of the SQLite variants table 
# and annotators in filter config. Must run
# this step, if a module in OpenCRAVAT does
# not have any annotations for a provided set
# of variants, then that modules annotations 
# may not exist in the SQLite table.
df = pd.read_sql_query("SELECT * FROM variant", conn)
table_var_annotators = set([col for col in df.columns])
filter_annotators = []
column2module = {{}}
for ann in set(filter.keys()):
    try:
        # Multiple column filters
        col_names = filter[ann]['cols']
        col_names = [c.strip() for c in col_names.split(',')]
    except KeyError:
        # One column filter 
        col_names = [filter[ann]['col'].strip()]
    for col in col_names:
        coln = '{{}}__{{}}'.format(ann, col)
        filter_annotators.append(coln)
        column2module[coln] = ann

filter_annotators = set(filter_annotators)
tmp_annotators = table_var_annotators.intersection(filter_annotators)
keep_annotators = set([column2module[ann] for ann in tmp_annotators])

# Sanity check 
if len(keep_annotators) == 0:
    print('WARNING: No filter annotators were provided that match oc run annotators.', file=sys.stderr)
    print('WARNING: The next filtering step may fail.', file=sys.stderr)

# Filter to avoid SQL filtering issues
filter = keep(filter, keep_annotators)
print('Apply final filters to SQLite: ', filter)

filter_query_nonnull = ' OR '.join([filterunit(annot) for annot in filter.keys()])
filter_query_null = ' AND '.join([filterunit_null(annot) for annot in filter.keys()])
filter_query = filter_query_nonnull + ' OR (' + filter_query_null + ')'
print(filter_query)
conn.execute('CREATE TABLE variant2 AS SELECT * FROM variant WHERE (' + filter_query + ')')
conn.execute('DROP TABLE variant')
conn.execute('ALTER TABLE variant2 RENAME TO variant')
conn.execute('DELETE from sample WHERE base__uid NOT IN (SELECT base__uid FROM variant)')
conn.execute('DELETE FROM gene WHERE base__hugo NOT IN (SELECT base__hugo FROM variant)')
conn.execute('DELETE FROM mapping WHERE base__uid NOT IN (SELECT base__uid FROM variant)')
conn.execute('UPDATE info SET colval = (SELECT COUNT(*) FROM variant) WHERE colkey == "Number of unique input variants"')
conn.execute('VACUUM')
conn.close()
EOF
    
# Create fix column script,
# Fixes columns to a min and max AF 
cp {output.filter_2} {output.fixed}
cat << EOF > {params.fixed}
import sqlite3
import os
import pandas as pd

conn = sqlite3.connect("{output.fixed}")
conn.isolation_level = None
cursor = conn.cursor()
depth = pd.read_sql_query('SELECT base__uid,vcfinfo__tot_reads,vcfinfo__af from variant', conn, index_col = 'base__uid')
tot_read = depth.vcfinfo__tot_reads.str.split(';', expand = True).astype('float')
af = depth.vcfinfo__af.str.split(';', expand = True).apply(pd.to_numeric)
depth['vcfinfo__Max_read'] = tot_read.max(axis = 1)
depth['vcfinfo__Min_read'] = tot_read.min(axis = 1)
depth['vcfinfo__Max_af'] = af.max(axis = 1)
depth['vcfinfo__Min_af'] = af.min(axis = 1)
depth.to_sql('tmp', conn, if_exists = 'replace', index = True)
conn.execute('alter table variant add column vcfinfo__Max_read numeric(50)')
conn.execute('alter table variant add column vcfinfo__Min_read numeric(50)')
conn.execute('alter table variant add column vcfinfo__Max_af numeric(50)')
conn.execute('alter table variant add column vcfinfo__Min_af numeric(50)')
qry = 'update variant set vcfinfo__Max_read = (select vcfinfo__Max_read from tmp where tmp.base__uid = variant.base__uid) where vcfinfo__Max_read is NULL'
conn.execute(qry)
qry = 'update variant set vcfinfo__Min_read = (select vcfinfo__Min_read from tmp where tmp.base__uid = variant.base__uid) where vcfinfo__Min_read is NULL'
conn.execute(qry)
qry = 'update variant set vcfinfo__Max_af = (select vcfinfo__Max_af from tmp where tmp.base__uid = variant.base__uid) where vcfinfo__Max_af is NULL'
conn.execute(qry)
qry = 'update variant set vcfinfo__Min_af = (select vcfinfo__Min_af from tmp where tmp.base__uid = variant.base__uid) where vcfinfo__Min_af is NULL'
conn.execute(qry)
conn.execute('''INSERT INTO variant_header (col_name, col_def) VALUES ('vcfinfo__Max_read','{{"index": null, "name": "vcfinfo__Max_read", "title": "Max reads", "type": "float", "categories": [], "width": 70, "desc": null, "hidden": false, "category": null, "filterable": true, "link_format": null, "genesummary": false, "table": false}}')''')
conn.execute('''INSERT INTO variant_header (col_name, col_def) VALUES ('vcfinfo__Min_read','{{"index": null, "name": "vcfinfo__Min_read", "title": "Min reads", "type": "float", "categories": [], "width": 70, "desc": null, "hidden": false, "category": null, "filterable": true, "link_format": null, "genesummary": false, "table": false}}')''')
conn.execute('''INSERT INTO variant_header (col_name, col_def) VALUES ('vcfinfo__Max_af','{{"index": null, "name": "vcfinfo__Max_af", "title": "Max AF", "type": "float", "categories": [], "width": 70, "desc": null, "hidden": false, "category": null, "filterable": true, "link_format": null, "genesummary": false, "table": false}}')''')
conn.execute('''INSERT INTO variant_header (col_name, col_def) VALUES ('vcfinfo__Min_af','{{"index": null, "name": "vcfinfo__Min_af", "title": "Min AF", "type": "float", "categories": [], "width": 70, "desc": null, "hidden": false, "category": null, "filterable": true, "link_format": null, "genesummary": false, "table": false}}')''')
conn.commit()
conn.execute('drop table tmp')
conn.execute('VACUUM')
conn.close()
EOF
    
echo 'Running first filtering script'
python3 {params.filter_1}

echo 'Running secondary filtering script'
python3 {params.filter_2}

echo 'Running column fixing script'
python3 {params.fixed}
"""


rule opencravat_germline_merge:
    """
    Merges the filtered, chromosone chunked SQLite files. The OpenCRAVAT run 
    command was scattered on each chromosomes (creating chunks) to speed up 
    its runtime. The step merges the resulting filtered, chunked SQLite files 
    into one SQLite file. This creates the final SQLite file that can be used 
    with OpenCRAVAT's user interface.
    @Input:
        Filtered, fixed chromosome chunked SQLite OpenCravat results (gather)
    @Output:
        Merged and filtered SQLite OpenCravat results
    """
    input: 
        dbs = expand(join(workpath, "OpenCRAVAT", "germline", "filter", "cravat_{chunk}.fixed.sqlite"), chunk=chunks),
    output: 
        merged = join(workpath, "OpenCRAVAT", "germline", "cravat.merged.sqlite"),
    params: 
        rname  = "ocmergegermline",
    threads: int(allocated("threads", "merge_sqlite", cluster))
    container: config['images']['open_cravat']
    envmodules: config['tools']['open_cravat']
    shell: """
    oc util mergesqlite \\
        -o {output.merged} \\
        {input.dbs} 
    """


# Somatic OpenCravat Rules
rule opencravat_somatic:
    """
    Performs genomic variant interpretation including variant impact, annotation,
    and scoring using OpenCRAVAT. Creates a SQLite database that can be used 
    with OpenCRAVAT's user interface. Here is more information about OpenCRAVAT: 
    https://open-cravat.readthedocs.io/en/latest/
    @Input:
        Per sample caller merged somatic VCF file (scatter)
    @Output:
        Per sample caller merged somatic SQLite OpenCravat results
    """
    input: 
        vcfs = expand(join(workpath, "merged", "somatic", "{name}.merged.filtered.norm.vcf.gz"), name=tumors),
    output: 
        db = join(workpath, "OpenCRAVAT", "somatic", "cravat_somatic.sqlite"),
    params: 
        rname  = "ocrunsomatic",
        prefix = "cravat_somatic",
        outdir = join(workpath, "OpenCRAVAT", "somatic"),
        annot  = ' '.join(config['options']['oc_annotators']),
        genome = config['references']['OC_LIFTOVER'],
        module = config['references']['OC_MODULES'],
    threads: int(allocated("threads", "opencravat_somatic", cluster))
    container: config['images']['open_cravat']
    envmodules: config['tools']['open_cravat']
    shell: """
    # Environment variable for modules dir
    export OC_MODULES="{params.module}"
 
    oc run \\
        -t vcf \\
        -x \\
        --newlog \\
        --cleanrun \\
        --system-option "modules_dir={params.module}" \\
        -a {params.annot} \\
        -n {params.prefix} \\
        -l {params.genome} \\
        -d {params.outdir} \\
        --mp {threads} \\
        {input.vcfs}
    """


rule opencravat_somatic_filter:
    """
    Performs additional filtering on the SQLite file generated by OpenCRAVAT.
    The filter options provided by OpenCRAVAT were not working correctly. An issue
    with the maintainers of the tool have been opened up. This rule is effectively
    a patch and may not be used in the near future. Each script that is generated
    performs additional rounds of filtering. 

    @filter_1: Filters variants based on sequence ontology and allele frequency 
    in public databases.
        @criteria: 
        Sequence ontology one of the given list of SO in the config file
            AND
        GNOMAD AF < 0.001 OR GNOMAD3 AF < 0.001 OR 1000Genome AF < 0.001 
            OR 
        all GNOMAD, GNOMAD3 and 1000Genome AF are missing
    
    @filter_2: Filter variants based on criteria given in the config.json 
    "secondary" group. To add filter move an annotator from "notused" group 
    to "secondary" group. Additional filter criterion can be added in the 
    config.json in the folloing format:
        "annotator": {
            "col" : "column of annotator to use"
            "relation" : "<, <=, >, >="  # for numeric values or "IN" for character values
            "value": "value to use for filter"
        }
    Note, if multiple column of same annotator need to be used for filtering using the 
    following format:
        "annotator": {
            "col": "multiple",
            "cols" : "col1,col2",
            "relation": "relation1,relation2",
            "value": "value1,value2"
        }
    
    @fix_column: By default, OpenCRAVAT has vcf_info total reads as string that includes 
    reads from all the samples that contains the variant. This rule creates an additional
    column with max and min of total reads and max and min of AF.
    @Input:
        Chromosome chunked SQLite OpenCravat results
    @Output:
        Filtered, fixed chromosome chunked SQLite OpenCravat results
    """
    input: 
        db = join(workpath, "OpenCRAVAT", "somatic", "cravat_somatic.sqlite"),
    output:
        filter_1 = join(workpath, "OpenCRAVAT", "somatic", "filter", "cravat_somatic.f1.sqlite"),
        filter_2 = join(workpath, "OpenCRAVAT", "somatic", "filter", "cravat_somatic.f2.sqlite"),
        fixed    = join(workpath, "OpenCRAVAT", "somatic", "cravat.merged.sqlite"),
    params: 
        rname  = "ocfiltersomatic",
        annot  = config['options']['oc_annotators'],
        scripts  = join(workpath, "OpenCRAVAT", "somatic", "scripts"),
        filter_1 = join(workpath, "OpenCRAVAT", "somatic", "scripts", "filter_1_somatic.py"),
        filter_2 = join(workpath, "OpenCRAVAT", "somatic", "scripts", "filter_2_somatic.py"),
        fixed    = join(workpath, "OpenCRAVAT", "somatic", "scripts", "fix_column_somatic.py"),
        # Default pop_maf: 0.05 
        maf_thres = config['options']['cravat_filters']['primary']['pop_maf'],
        so = config['options']['cravat_filters']['primary']['so'],
        secondary = config['options']['cravat_filters']['secondary'],
    message: "Running OpenCRAVAT filters on '{input.db}' input file"
    threads: int(allocated("threads", "opencravat_somatic_filter", cluster))
    container: config['images']['genome-seek']
    envmodules: 
        # Requires sqlite3, added in python/3.5
        config['tools']['python3']
    shell: """
# Create first filtering script,
# Filters based on AF 
mkdir -p {params.scripts}
cp {input.db} {output.filter_1} 
cat << EOF > {params.filter_1}
import sqlite3
import os

maf = str({params.maf_thres})
mafc = str(1 - float({params.maf_thres}))
so = "{params.so}"
conn = sqlite3.connect("{output.filter_1}")
conn.isolation_level = None
cursor = conn.cursor()
conn.execute('CREATE TABLE variant2 AS SELECT * FROM variant WHERE (base__so IN (' + '"' + '", "'.join(so.split(',')) + '"' + ')) AND ((gnomad__af IS NULL AND gnomad3__af IS NULL AND thousandgenomes__af IS NULL) OR (gnomad__af <= ' + maf +' OR gnomad__af >= '+mafc+' OR gnomad3__af <= '+maf+' OR gnomad3__af >= '+mafc+' OR thousandgenomes__af <= '+maf+' OR thousandgenomes__af >= '+mafc+'))')
conn.execute('DROP TABLE variant')
conn.execute('ALTER TABLE variant2 RENAME TO variant')
conn.execute('DELETE from sample WHERE base__uid NOT IN (SELECT base__uid FROM variant)')
conn.execute('DELETE FROM gene WHERE base__hugo NOT IN (SELECT base__hugo FROM variant)')
conn.execute('DELETE FROM mapping WHERE base__uid NOT IN (SELECT base__uid FROM variant)')
conn.execute('UPDATE info SET colval = (SELECT COUNT(*) FROM variant) WHERE colkey == "Number of unique input variants"')
conn.execute('VACUUM')
conn.close()
EOF

# Create second filtering script,
# Filters based on filters in config
cp {output.filter_1} {output.filter_2}
cat << EOF > {params.filter_2}
import pandas as pd
import sqlite3
import os

conn = sqlite3.connect("{output.filter_2}")
conn.isolation_level = None
cursor = conn.cursor()
filter = {params.secondary}

def keep(dd, used_annotators):
    final_annotators = {{annotator: dd[annotator] for annotator in used_annotators}}
    return final_annotators

def filtercol(dd, annot):
    if dd['relation']=='IN':
        return annot + '__' + dd['col'] + ' ' + dd['relation'] + ' ("' + '", "'.join(dd['value'].split(',')) + '")'
    elif dd['relation']=='IS' or dd['relation']=='IS NOT':
        return annot + '__' + dd['col'] + ' ' + dd['relation'] + ' ' + dd['value']
    else:
        return annot + '__'+ dd['col'] + ' ' + dd['relation'] + dd['value']    

def filterunit(annot):
    dd = filter[annot]
    if dd['col'].lower()=='multiple':
        cols = dd['cols'].split(',')
        relations = dd['relation'].split(',')
        values = dd['value'].split(',')
        return(' OR '.join([filtercol({{'col':cols[0], 'relation': relations[0], 'value': values[0]}}, annot) for i in range(len(cols))]))
    else:
        return(filtercol(dd, annot))

def filterunit_null(annot):
    dd = filter[annot]
    if dd['col'].lower()=='multiple':
        cols = dd['cols'].split(',')
        relations = dd['relation'].split(',')
        values = dd['value'].split(',')
        return(' AND '.join([annot + '__' + cols[i] + ' IS NULL' for i in range(len(cols))]))
    else:
        return(annot + '__' + dd['col'] + ' IS NULL')

# Find the intersect of annotators listed
# in colnames of the SQLite variants table 
# and annotators in filter config. Must run
# this step, if a module in OpenCRAVAT does
# not have any annotations for a provided set
# of variants, then that modules annotations 
# may not exist in the SQLite table.
df = pd.read_sql_query("SELECT * FROM variant", conn)
table_var_annotators = set([col for col in df.columns])
filter_annotators = []
column2module = {{}}
for ann in set(filter.keys()):
    try:
        # Multiple column filters
        col_names = filter[ann]['cols']
        col_names = [c.strip() for c in col_names.split(',')]
    except KeyError:
        # One column filter 
        col_names = [filter[ann]['col'].strip()]
    for col in col_names:
        coln = '{{}}__{{}}'.format(ann, col)
        filter_annotators.append(coln)
        column2module[coln] = ann

filter_annotators = set(filter_annotators)
tmp_annotators = table_var_annotators.intersection(filter_annotators)
keep_annotators = set([column2module[ann] for ann in tmp_annotators])

# Sanity check 
if len(keep_annotators) == 0:
    print('WARNING: No filter annotators were provided that match oc run annotators.', file=sys.stderr)
    print('WARNING: The next filtering step may fail.', file=sys.stderr)

# Filter to avoid SQL filtering issues
filter = keep(filter, keep_annotators)
print('Apply final filters to SQLite: ', filter)

filter_query_nonnull = ' OR '.join([filterunit(annot) for annot in filter.keys()])
filter_query_null = ' AND '.join([filterunit_null(annot) for annot in filter.keys()])
filter_query = filter_query_nonnull + ' OR (' + filter_query_null + ')'
print(filter_query)
conn.execute('CREATE TABLE variant2 AS SELECT * FROM variant WHERE (' + filter_query + ')')
conn.execute('DROP TABLE variant')
conn.execute('ALTER TABLE variant2 RENAME TO variant')
conn.execute('DELETE from sample WHERE base__uid NOT IN (SELECT base__uid FROM variant)')
conn.execute('DELETE FROM gene WHERE base__hugo NOT IN (SELECT base__hugo FROM variant)')
conn.execute('DELETE FROM mapping WHERE base__uid NOT IN (SELECT base__uid FROM variant)')
conn.execute('UPDATE info SET colval = (SELECT COUNT(*) FROM variant) WHERE colkey == "Number of unique input variants"')
conn.execute('VACUUM')
conn.close()
EOF
    
# Create fix column script,
# Fixes columns to a min and max AF 
cp {output.filter_2} {output.fixed}
cat << EOF > {params.fixed}
import sqlite3
import os
import pandas as pd

conn = sqlite3.connect("{output.fixed}")
conn.isolation_level = None
cursor = conn.cursor()
depth = pd.read_sql_query('SELECT base__uid,vcfinfo__tot_reads,vcfinfo__af from variant', conn, index_col = 'base__uid')
tot_read = depth.vcfinfo__tot_reads.str.split(';', expand = True).astype('float')
af = depth.vcfinfo__af.str.split(';', expand = True).apply(pd.to_numeric)
depth['vcfinfo__Max_read'] = tot_read.max(axis = 1)
depth['vcfinfo__Min_read'] = tot_read.min(axis = 1)
depth['vcfinfo__Max_af'] = af.max(axis = 1)
depth['vcfinfo__Min_af'] = af.min(axis = 1)
depth.to_sql('tmp', conn, if_exists = 'replace', index = True)
conn.execute('alter table variant add column vcfinfo__Max_read numeric(50)')
conn.execute('alter table variant add column vcfinfo__Min_read numeric(50)')
conn.execute('alter table variant add column vcfinfo__Max_af numeric(50)')
conn.execute('alter table variant add column vcfinfo__Min_af numeric(50)')
qry = 'update variant set vcfinfo__Max_read = (select vcfinfo__Max_read from tmp where tmp.base__uid = variant.base__uid) where vcfinfo__Max_read is NULL'
conn.execute(qry)
qry = 'update variant set vcfinfo__Min_read = (select vcfinfo__Min_read from tmp where tmp.base__uid = variant.base__uid) where vcfinfo__Min_read is NULL'
conn.execute(qry)
qry = 'update variant set vcfinfo__Max_af = (select vcfinfo__Max_af from tmp where tmp.base__uid = variant.base__uid) where vcfinfo__Max_af is NULL'
conn.execute(qry)
qry = 'update variant set vcfinfo__Min_af = (select vcfinfo__Min_af from tmp where tmp.base__uid = variant.base__uid) where vcfinfo__Min_af is NULL'
conn.execute(qry)
conn.execute('''INSERT INTO variant_header (col_name, col_def) VALUES ('vcfinfo__Max_read','{{"index": null, "name": "vcfinfo__Max_read", "title": "Max reads", "type": "float", "categories": [], "width": 70, "desc": null, "hidden": false, "category": null, "filterable": true, "link_format": null, "genesummary": false, "table": false}}')''')
conn.execute('''INSERT INTO variant_header (col_name, col_def) VALUES ('vcfinfo__Min_read','{{"index": null, "name": "vcfinfo__Min_read", "title": "Min reads", "type": "float", "categories": [], "width": 70, "desc": null, "hidden": false, "category": null, "filterable": true, "link_format": null, "genesummary": false, "table": false}}')''')
conn.execute('''INSERT INTO variant_header (col_name, col_def) VALUES ('vcfinfo__Max_af','{{"index": null, "name": "vcfinfo__Max_af", "title": "Max AF", "type": "float", "categories": [], "width": 70, "desc": null, "hidden": false, "category": null, "filterable": true, "link_format": null, "genesummary": false, "table": false}}')''')
conn.execute('''INSERT INTO variant_header (col_name, col_def) VALUES ('vcfinfo__Min_af','{{"index": null, "name": "vcfinfo__Min_af", "title": "Min AF", "type": "float", "categories": [], "width": 70, "desc": null, "hidden": false, "category": null, "filterable": true, "link_format": null, "genesummary": false, "table": false}}')''')
conn.commit()
conn.execute('drop table tmp')
conn.execute('VACUUM')
conn.close()
EOF
    
echo 'Running first filtering script'
python3 {params.filter_1}

echo 'Running secondary filtering script'
python3 {params.filter_2}

echo 'Running column fixing script'
python3 {params.fixed}
"""
